{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46400000e+01, -5.81175390e+00,  6.36685342e-01,\n",
       "         6.19221604e+00, -1.15071381e+01,  1.00000000e+00],\n",
       "       [ 1.46000000e+01, -5.78342895e+00,  7.31903182e-01,\n",
       "         6.21419775e+00, -1.17001451e+01,  9.99903973e-01],\n",
       "       [ 1.47700000e+01, -5.43087604e+00,  4.68770338e-01,\n",
       "         6.19965281e+00, -1.19755612e+01,  9.99819949e-01],\n",
       "       ...,\n",
       "       [-1.23300000e+01,  2.87980737e+01,  5.01755314e+00,\n",
       "         7.37128378e-01,  1.71325347e+01,  2.52618250e-02],\n",
       "       [-1.19500000e+01,  2.71486407e+01,  4.41601929e+00,\n",
       "         5.57340390e-01,  1.71083923e+01,  1.91760840e-02],\n",
       "       [-1.21900000e+01,  2.88853817e+01,  4.79346515e+00,\n",
       "        -2.45112209e-01,  1.84495653e+01,  1.30138220e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.genfromtxt('meanfac6 .csv',delimiter = ',')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B,C,D,E,F = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_data)):\n",
    "    A.append(raw_data[i][0])\n",
    "    B.append(raw_data[i][1])\n",
    "    C.append(raw_data[i][2])\n",
    "    D.append(raw_data[i][3])\n",
    "    E.append(raw_data[i][4])\n",
    "    F.append(raw_data[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.64],\n",
       "       [ 14.6 ],\n",
       "       [ 14.77],\n",
       "       ...,\n",
       "       [-12.33],\n",
       "       [-11.95],\n",
       "       [-12.19]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(A).reshape(-1,1)\n",
    "y = np.array(F).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = []\n",
    "__ = []\n",
    "for i in range(len(A)):\n",
    "    _.append(int(A[i]))\n",
    "    __.append(int(F[i]))\n",
    "A = _\n",
    "F = __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.999903973,\n",
       " 0.999819949,\n",
       " 0.999717919,\n",
       " 0.999636896,\n",
       " 0.999566876,\n",
       " 0.999522864,\n",
       " 0.998435553,\n",
       " 0.99842555,\n",
       " 0.998405544,\n",
       " 0.998375535,\n",
       " 0.998345527,\n",
       " 0.998315518,\n",
       " 0.99828551,\n",
       " 0.996324949,\n",
       " 0.996304943,\n",
       " 0.996274935,\n",
       " 0.996244926,\n",
       " 0.99622492,\n",
       " 0.996204915,\n",
       " 0.9961549,\n",
       " 0.996104886,\n",
       " 0.996054872,\n",
       " 0.996004857,\n",
       " 0.995994855,\n",
       " 0.99594484,\n",
       " 0.995934837,\n",
       " 0.995844812,\n",
       " 0.995724777,\n",
       " 0.995574734,\n",
       " 0.995424691,\n",
       " 0.995274649,\n",
       " 0.993734208,\n",
       " 0.993664188,\n",
       " 0.993584165,\n",
       " 0.993504142,\n",
       " 0.993424119,\n",
       " 0.993344096,\n",
       " 0.993144039,\n",
       " 0.992013716,\n",
       " 0.991863673,\n",
       " 0.991833664,\n",
       " 0.991803656,\n",
       " 0.991763644,\n",
       " 0.991743639,\n",
       " 0.991733636,\n",
       " 0.991703627,\n",
       " 0.99164361,\n",
       " 0.99143355,\n",
       " 0.991093453,\n",
       " 0.990763358,\n",
       " 0.990393252,\n",
       " 0.99000074,\n",
       " 0.989530906,\n",
       " 0.989342452,\n",
       " 0.989141394,\n",
       " 0.988905827,\n",
       " 0.988691366,\n",
       " 0.988471803,\n",
       " 0.988328762,\n",
       " 0.988239036,\n",
       " 0.988228933,\n",
       " 0.988073189,\n",
       " 0.987889937,\n",
       " 0.987771003,\n",
       " 0.987701983,\n",
       " 0.98755384,\n",
       " 0.987466515,\n",
       " 0.987400597,\n",
       " 0.987187536,\n",
       " 0.987086807,\n",
       " 0.986844037,\n",
       " 0.986842237,\n",
       " 0.986751711,\n",
       " 0.986615472,\n",
       " 0.986615172,\n",
       " 0.986605869,\n",
       " 0.986551854,\n",
       " 0.986506841,\n",
       " 0.986412814,\n",
       " 0.986311285,\n",
       " 0.986180848,\n",
       " 0.986096123,\n",
       " 0.985981991,\n",
       " 0.985894666,\n",
       " 0.985817544,\n",
       " 0.985817244,\n",
       " 0.98580344,\n",
       " 0.985787135,\n",
       " 0.985784334,\n",
       " 0.985731519,\n",
       " 0.985729419,\n",
       " 0.985673203,\n",
       " 0.985659899,\n",
       " 0.985620587,\n",
       " 0.985002411,\n",
       " 0.984990007,\n",
       " 0.984907283,\n",
       " 0.984838464,\n",
       " 0.984775946,\n",
       " 0.984679518,\n",
       " 0.98458149,\n",
       " 0.983027746,\n",
       " 0.98279768,\n",
       " 0.982794879,\n",
       " 0.982595722,\n",
       " 0.982576717,\n",
       " 0.982569415,\n",
       " 0.982360455,\n",
       " 0.982334048,\n",
       " 0.982316142,\n",
       " 0.982074773,\n",
       " 0.982069972,\n",
       " 0.982024259,\n",
       " 0.98188792,\n",
       " 0.981789592,\n",
       " 0.981689963,\n",
       " 0.981633447,\n",
       " 0.981442793,\n",
       " 0.981412784,\n",
       " 0.981253238,\n",
       " 0.981087991,\n",
       " 0.980897837,\n",
       " 0.980889534,\n",
       " 0.980708083,\n",
       " 0.980671272,\n",
       " 0.980553538,\n",
       " 0.980459011,\n",
       " 0.980439206,\n",
       " 0.980417599,\n",
       " 0.980345079,\n",
       " 0.980286162,\n",
       " 0.980282161,\n",
       " 0.980270957,\n",
       " 0.980264556,\n",
       " 0.980235647,\n",
       " 0.980229346,\n",
       " 0.98013912,\n",
       " 0.98013842,\n",
       " 0.98010421,\n",
       " 0.980073401,\n",
       " 0.980021986,\n",
       " 0.979945865,\n",
       " 0.979899951,\n",
       " 0.979897751,\n",
       " 0.979723101,\n",
       " 0.979711898,\n",
       " 0.979671486,\n",
       " 0.979461926,\n",
       " 0.979448922,\n",
       " 0.97912513,\n",
       " 0.9772718,\n",
       " 0.977267298,\n",
       " 0.977252394,\n",
       " 0.977239691,\n",
       " 0.97720348,\n",
       " 0.977193977,\n",
       " 0.977114455,\n",
       " 0.97590891,\n",
       " 0.975893005,\n",
       " 0.975883903,\n",
       " 0.975850793,\n",
       " 0.975781273,\n",
       " 0.975654937,\n",
       " 0.975506295,\n",
       " 0.974674557,\n",
       " 0.974395777,\n",
       " 0.974218927,\n",
       " 0.974175514,\n",
       " 0.973942348,\n",
       " 0.973894734,\n",
       " 0.973822813,\n",
       " 0.973728386,\n",
       " 0.973537332,\n",
       " 0.973437103,\n",
       " 0.973426,\n",
       " 0.973361581,\n",
       " 0.973326071,\n",
       " 0.973157923,\n",
       " 0.973131115,\n",
       " 0.973036288,\n",
       " 0.97290305,\n",
       " 0.972840732,\n",
       " 0.9727276,\n",
       " 0.972629372,\n",
       " 0.972575557,\n",
       " 0.972562653,\n",
       " 0.972529543,\n",
       " 0.972439618,\n",
       " 0.972309981,\n",
       " 0.972302278,\n",
       " 0.972294076,\n",
       " 0.972040404,\n",
       " 0.972033201,\n",
       " 0.971955979,\n",
       " 0.971615982,\n",
       " 0.971281987,\n",
       " 0.970890675,\n",
       " 0.970463953,\n",
       " 0.970446748,\n",
       " 0.970442947,\n",
       " 0.970412738,\n",
       " 0.970396133,\n",
       " 0.970317711,\n",
       " 0.970304807,\n",
       " 0.970195276,\n",
       " 0.969908094,\n",
       " 0.96989589,\n",
       " 0.969637116,\n",
       " 0.969386745,\n",
       " 0.968903106,\n",
       " 0.968620525,\n",
       " 0.968508693,\n",
       " 0.968396161,\n",
       " 0.967218524,\n",
       " 0.967154806,\n",
       " 0.967111994,\n",
       " 0.967101591,\n",
       " 0.96706448,\n",
       " 0.966963151,\n",
       " 0.966937344,\n",
       " 0.966902234,\n",
       " 0.966843117,\n",
       " 0.966756392,\n",
       " 0.966613852,\n",
       " 0.966448704,\n",
       " 0.966419996,\n",
       " 0.966193431,\n",
       " 0.965974869,\n",
       " 0.965766509,\n",
       " 0.965754006,\n",
       " 0.965747304,\n",
       " 0.965504234,\n",
       " 0.965024997,\n",
       " 0.964994188,\n",
       " 0.964948475,\n",
       " 0.964924268,\n",
       " 0.964851247,\n",
       " 0.964835443,\n",
       " 0.964816738,\n",
       " 0.964715409,\n",
       " 0.964698904,\n",
       " 0.964639887,\n",
       " 0.964628784,\n",
       " 0.964411422,\n",
       " 0.964325597,\n",
       " 0.964184257,\n",
       " 0.964138444,\n",
       " 0.964089129,\n",
       " 0.964064923,\n",
       " 0.964039715,\n",
       " 0.9639861,\n",
       " 0.963980298,\n",
       " 0.963875268,\n",
       " 0.963730927,\n",
       " 0.963683313,\n",
       " 0.96353067,\n",
       " 0.963516966,\n",
       " 0.963470753,\n",
       " 0.963275897,\n",
       " 0.963211679,\n",
       " 0.963105348,\n",
       " 0.962970009,\n",
       " 0.962957106,\n",
       " 0.962938,\n",
       " 0.962850075,\n",
       " 0.962772753,\n",
       " 0.962649718,\n",
       " 0.962646717,\n",
       " 0.962571996,\n",
       " 0.96255159,\n",
       " 0.962534185,\n",
       " 0.962493373,\n",
       " 0.962487872,\n",
       " 0.962487471,\n",
       " 0.962450961,\n",
       " 0.962415951,\n",
       " 0.96237794,\n",
       " 0.962369338,\n",
       " 0.962367737,\n",
       " 0.962310221,\n",
       " 0.962298217,\n",
       " 0.962296417,\n",
       " 0.962293916,\n",
       " 0.962285414,\n",
       " 0.962233899,\n",
       " 0.962176583,\n",
       " 0.962149875,\n",
       " 0.962146674,\n",
       " 0.962136971,\n",
       " 0.962009035,\n",
       " 0.962007734,\n",
       " 0.961921309,\n",
       " 0.961895502,\n",
       " 0.961824082,\n",
       " 0.961629526,\n",
       " 0.961606119,\n",
       " 0.961599818,\n",
       " 0.961543601,\n",
       " 0.961491086,\n",
       " 0.96139696,\n",
       " 0.961374053,\n",
       " 0.961344845,\n",
       " 0.961344445,\n",
       " 0.961167594,\n",
       " 0.961110578,\n",
       " 0.960743873,\n",
       " 0.960482598,\n",
       " 0.960222824,\n",
       " 0.960182912,\n",
       " 0.959995259,\n",
       " 0.959935842,\n",
       " 0.959727382,\n",
       " 0.959665564,\n",
       " 0.959630954,\n",
       " 0.959561635,\n",
       " 0.959543029,\n",
       " 0.959522423,\n",
       " 0.959462506,\n",
       " 0.959317765,\n",
       " 0.95912601,\n",
       " 0.959052289,\n",
       " 0.958744501,\n",
       " 0.958703589,\n",
       " 0.958444315,\n",
       " 0.95814713,\n",
       " 0.95758837,\n",
       " 0.957579268,\n",
       " 0.957442028,\n",
       " 0.957344,\n",
       " 0.957229868,\n",
       " 0.956937484,\n",
       " 0.956875466,\n",
       " 0.956577481,\n",
       " 0.956557075,\n",
       " 0.956409333,\n",
       " 0.956088041,\n",
       " 0.955981311,\n",
       " 0.955871279,\n",
       " 0.955458061,\n",
       " 0.955336926,\n",
       " 0.955006832,\n",
       " 0.954540899,\n",
       " 0.95433524,\n",
       " 0.953743671,\n",
       " 0.953316549,\n",
       " 0.953291841,\n",
       " 0.953253631,\n",
       " 0.953195714,\n",
       " 0.953141899,\n",
       " 0.953125594,\n",
       " 0.953085482,\n",
       " 0.953052973,\n",
       " 0.952905831,\n",
       " 0.952878923,\n",
       " 0.952759689,\n",
       " 0.952673365,\n",
       " 0.952629052,\n",
       " 0.95258854,\n",
       " 0.95255103,\n",
       " 0.952434396,\n",
       " 0.952425094,\n",
       " 0.952375579,\n",
       " 0.952324165,\n",
       " 0.952299058,\n",
       " 0.952211232,\n",
       " 0.952179023,\n",
       " 0.951997371,\n",
       " 0.951836325,\n",
       " 0.951805716,\n",
       " 0.951793513,\n",
       " 0.951510832,\n",
       " 0.95143271,\n",
       " 0.951332881,\n",
       " 0.951211246,\n",
       " 0.951167534,\n",
       " 0.951127322,\n",
       " 0.951078909,\n",
       " 0.951040798,\n",
       " 0.951007088,\n",
       " 0.950974679,\n",
       " 0.950692198,\n",
       " 0.950526351,\n",
       " 0.950510246,\n",
       " 0.950407316,\n",
       " 0.950078222,\n",
       " 0.94961599,\n",
       " 0.949321606,\n",
       " 0.949295599,\n",
       " 0.949284295,\n",
       " 0.949137553,\n",
       " 0.949049928,\n",
       " 0.94902022,\n",
       " 0.949017919,\n",
       " 0.949001514,\n",
       " 0.948948899,\n",
       " 0.948858674,\n",
       " 0.948765947,\n",
       " 0.948720234,\n",
       " 0.948625007,\n",
       " 0.948570691,\n",
       " 0.948364832,\n",
       " 0.948227693,\n",
       " 0.948211689,\n",
       " 0.948057044,\n",
       " 0.948043941,\n",
       " 0.947497084,\n",
       " 0.947267719,\n",
       " 0.947119276,\n",
       " 0.947114375,\n",
       " 0.947092869,\n",
       " 0.947088367,\n",
       " 0.947079965,\n",
       " 0.947031751,\n",
       " 0.947015246,\n",
       " 0.946932123,\n",
       " 0.946849199,\n",
       " 0.946820291,\n",
       " 0.946732165,\n",
       " 0.946704858,\n",
       " 0.946683151,\n",
       " 0.946594926,\n",
       " 0.946589825,\n",
       " 0.946548013,\n",
       " 0.946479393,\n",
       " 0.94636306,\n",
       " 0.946301342,\n",
       " 0.94625973,\n",
       " 0.946202114,\n",
       " 0.946072177,\n",
       " 0.946054572,\n",
       " 0.945995655,\n",
       " 0.945867918,\n",
       " 0.945863717,\n",
       " 0.945848013,\n",
       " 0.945821705,\n",
       " 0.945701571,\n",
       " 0.945651456,\n",
       " 0.945600942,\n",
       " 0.945434294,\n",
       " 0.945394783,\n",
       " 0.945389381,\n",
       " 0.945343268,\n",
       " 0.945332065,\n",
       " 0.945288252,\n",
       " 0.945250742,\n",
       " 0.945203328,\n",
       " 0.945122005,\n",
       " 0.945114303,\n",
       " 0.944994869,\n",
       " 0.944987967,\n",
       " 0.944980464,\n",
       " 0.944978764,\n",
       " 0.944874934,\n",
       " 0.944864331,\n",
       " 0.944813717,\n",
       " 0.9447539,\n",
       " 0.944751799,\n",
       " 0.944727092,\n",
       " 0.94468628,\n",
       " 0.944652671,\n",
       " 0.944646369,\n",
       " 0.944633165,\n",
       " 0.944574748,\n",
       " 0.94451023,\n",
       " 0.944373091,\n",
       " 0.944306372,\n",
       " 0.94430127,\n",
       " 0.944292668,\n",
       " 0.944247755,\n",
       " 0.944058001,\n",
       " 0.9440571,\n",
       " 0.943976477,\n",
       " 0.943949169,\n",
       " 0.943853442,\n",
       " 0.943772919,\n",
       " 0.943661687,\n",
       " 0.943339795,\n",
       " 0.943297883,\n",
       " 0.943228563,\n",
       " 0.94307842,\n",
       " 0.942965388,\n",
       " 0.942892367,\n",
       " 0.942745425,\n",
       " 0.942712216,\n",
       " 0.942667803,\n",
       " 0.942663402,\n",
       " 0.942647697,\n",
       " 0.942634593,\n",
       " 0.942627892,\n",
       " 0.942487551,\n",
       " 0.942313602,\n",
       " 0.941758043,\n",
       " 0.941654213,\n",
       " 0.94136253,\n",
       " 0.941334722,\n",
       " 0.941265202,\n",
       " 0.941115059,\n",
       " 0.941055542,\n",
       " 0.940951312,\n",
       " 0.94080367,\n",
       " 0.940801869,\n",
       " 0.940709043,\n",
       " 0.940617817,\n",
       " 0.940582207,\n",
       " 0.940499683,\n",
       " 0.940435865,\n",
       " 0.940361243,\n",
       " 0.940344539,\n",
       " 0.940343938,\n",
       " 0.940310629,\n",
       " 0.940241109,\n",
       " 0.940212801,\n",
       " 0.940207899,\n",
       " 0.940186093,\n",
       " 0.940181892,\n",
       " 0.940176691,\n",
       " 0.940087565,\n",
       " 0.940064959,\n",
       " 0.940060357,\n",
       " 0.940055856,\n",
       " 0.939898811,\n",
       " 0.939700054,\n",
       " 0.939643438,\n",
       " 0.939599926,\n",
       " 0.939569817,\n",
       " 0.939505299,\n",
       " 0.939477691,\n",
       " 0.939472089,\n",
       " 0.939345653,\n",
       " 0.939187608,\n",
       " 0.939136193,\n",
       " 0.939119588,\n",
       " 0.93909128,\n",
       " 0.939010357,\n",
       " 0.939000854,\n",
       " 0.938973046,\n",
       " 0.93884601,\n",
       " 0.938823704,\n",
       " 0.938730677,\n",
       " 0.938723775,\n",
       " 0.93866996,\n",
       " 0.938632149,\n",
       " 0.938624947,\n",
       " 0.938574032,\n",
       " 0.938424489,\n",
       " 0.938334864,\n",
       " 0.938281749,\n",
       " 0.938204827,\n",
       " 0.938196024,\n",
       " 0.938177419,\n",
       " 0.938091694,\n",
       " 0.938087593,\n",
       " 0.93804278,\n",
       " 0.938037679,\n",
       " 0.938018573,\n",
       " 0.937998968,\n",
       " 0.937993866,\n",
       " 0.937911243,\n",
       " 0.937835621,\n",
       " 0.93769238,\n",
       " 0.937671474,\n",
       " 0.937611957,\n",
       " 0.937488022,\n",
       " 0.937477218,\n",
       " 0.937390594,\n",
       " 0.937324575,\n",
       " 0.937282763,\n",
       " 0.937159328,\n",
       " 0.937101911,\n",
       " 0.937079605,\n",
       " 0.93699268,\n",
       " 0.936879948,\n",
       " 0.936535449,\n",
       " 0.936512343,\n",
       " 0.936493437,\n",
       " 0.936442523,\n",
       " 0.936360099,\n",
       " 0.936346195,\n",
       " 0.936306384,\n",
       " 0.936278976,\n",
       " 0.936137935,\n",
       " 0.936097724,\n",
       " 0.936023303,\n",
       " 0.935857655,\n",
       " 0.935652297,\n",
       " 0.935647195,\n",
       " 0.935482248,\n",
       " 0.935392322,\n",
       " 0.934913585,\n",
       " 0.934874574,\n",
       " 0.934844866,\n",
       " 0.934836763,\n",
       " 0.934738735,\n",
       " 0.934702325,\n",
       " 0.934673717,\n",
       " 0.934655211,\n",
       " 0.934638807,\n",
       " 0.934613099,\n",
       " 0.934606998,\n",
       " 0.934563385,\n",
       " 0.934562785,\n",
       " 0.934540178,\n",
       " 0.934539178,\n",
       " 0.934520573,\n",
       " 0.934486663,\n",
       " 0.934449553,\n",
       " 0.934425246,\n",
       " 0.934397938,\n",
       " 0.934323917,\n",
       " 0.934204082,\n",
       " 0.934179375,\n",
       " 0.93415997,\n",
       " 0.934137063,\n",
       " 0.934130061,\n",
       " 0.93402263,\n",
       " 0.933843679,\n",
       " 0.933749652,\n",
       " 0.93374205,\n",
       " 0.933703739,\n",
       " 0.933648023,\n",
       " 0.933606511,\n",
       " 0.933445866,\n",
       " 0.933377746,\n",
       " 0.93335634,\n",
       " 0.933309226,\n",
       " 0.93328542,\n",
       " 0.933214299,\n",
       " 0.932939821,\n",
       " 0.932929018,\n",
       " 0.932911213,\n",
       " 0.932501896,\n",
       " 0.93202776,\n",
       " 0.931798594,\n",
       " 0.931450995,\n",
       " 0.931424187,\n",
       " 0.931217028,\n",
       " 0.931143307,\n",
       " 0.93104928,\n",
       " 0.930916942,\n",
       " 0.930887634,\n",
       " 0.930842521,\n",
       " 0.930717485,\n",
       " 0.930687977,\n",
       " 0.930635062,\n",
       " 0.930596251,\n",
       " 0.930589349,\n",
       " 0.930494221,\n",
       " 0.930469814,\n",
       " 0.930445808,\n",
       " 0.930445507,\n",
       " 0.930301766,\n",
       " 0.930215142,\n",
       " 0.930067899,\n",
       " 0.930042192,\n",
       " 0.929928259,\n",
       " 0.929917756,\n",
       " 0.929830532,\n",
       " 0.929822829,\n",
       " 0.929725101,\n",
       " 0.929713698,\n",
       " 0.929607868,\n",
       " 0.929525444,\n",
       " 0.929521543,\n",
       " 0.929462126,\n",
       " 0.929414012,\n",
       " 0.929305581,\n",
       " 0.929179445,\n",
       " 0.92915994,\n",
       " 0.929147036,\n",
       " 0.929063612,\n",
       " 0.928941177,\n",
       " 0.928896965,\n",
       " 0.928891563,\n",
       " 0.928734118,\n",
       " 0.928692206,\n",
       " 0.928674301,\n",
       " 0.928578573,\n",
       " 0.928406824,\n",
       " 0.92835651,\n",
       " 0.928338005,\n",
       " 0.928293992,\n",
       " 0.928272186,\n",
       " 0.928227873,\n",
       " 0.92821767,\n",
       " 0.928204066,\n",
       " 0.928160854,\n",
       " 0.928136847,\n",
       " 0.927919385,\n",
       " 0.927840462,\n",
       " 0.927799051,\n",
       " 0.927740034,\n",
       " 0.927681517,\n",
       " 0.927524572,\n",
       " 0.92744725,\n",
       " 0.927221185,\n",
       " 0.926868084,\n",
       " 0.926785561,\n",
       " 0.926584903,\n",
       " 0.926498579,\n",
       " 0.926408753,\n",
       " 0.926392748,\n",
       " 0.925984231,\n",
       " 0.925929016,\n",
       " 0.925896806,\n",
       " 0.925765169,\n",
       " 0.925748964,\n",
       " 0.925542405,\n",
       " 0.925436475,\n",
       " 0.925194106,\n",
       " 0.922360595,\n",
       " 0.922179743,\n",
       " 0.922127128,\n",
       " 0.922109823,\n",
       " 0.921962781,\n",
       " 0.921938374,\n",
       " 0.921880558,\n",
       " 0.921849449,\n",
       " 0.921810338,\n",
       " 0.921786131,\n",
       " 0.921752421,\n",
       " 0.921701707,\n",
       " 0.921690604,\n",
       " 0.921665996,\n",
       " 0.921649992,\n",
       " 0.921630386,\n",
       " 0.921514953,\n",
       " 0.921495548,\n",
       " 0.921406522,\n",
       " 0.921405422,\n",
       " 0.9213286,\n",
       " 0.9213276,\n",
       " 0.921314696,\n",
       " 0.921214867,\n",
       " 0.921175956,\n",
       " 0.921112938,\n",
       " 0.92104782,\n",
       " 0.921045719,\n",
       " 0.92094249,\n",
       " 0.920897477,\n",
       " 0.920889474,\n",
       " 0.920860466,\n",
       " 0.920810152,\n",
       " 0.920781644,\n",
       " 0.920732029,\n",
       " 0.920563081,\n",
       " 0.920486259,\n",
       " 0.920376528,\n",
       " 0.920319011,\n",
       " 0.920290803,\n",
       " 0.920288803,\n",
       " 0.920121555,\n",
       " 0.920075242,\n",
       " 0.920028528,\n",
       " 0.919992118,\n",
       " 0.919838474,\n",
       " 0.919827471,\n",
       " 0.919584901,\n",
       " 0.919557593,\n",
       " 0.919542589,\n",
       " 0.919528785,\n",
       " 0.919471569,\n",
       " 0.919460266,\n",
       " 0.919435759,\n",
       " 0.919428957,\n",
       " 0.919367539,\n",
       " 0.919311623,\n",
       " 0.919287116,\n",
       " 0.919278214,\n",
       " 0.919203592,\n",
       " 0.919182986,\n",
       " 0.919175184,\n",
       " 0.919172583,\n",
       " 0.919050248,\n",
       " 0.918947619,\n",
       " 0.918927813,\n",
       " 0.918923812,\n",
       " 0.91881288,\n",
       " 0.918808779,\n",
       " 0.918795275,\n",
       " 0.918762066,\n",
       " 0.918729357,\n",
       " 0.918693746,\n",
       " 0.918658436,\n",
       " 0.91860222,\n",
       " 0.918421969,\n",
       " 0.918363752,\n",
       " 0.918354749,\n",
       " 0.918168896,\n",
       " 0.917933529,\n",
       " 0.917907722,\n",
       " 0.917879113,\n",
       " 0.917836901,\n",
       " 0.917806193,\n",
       " 0.917771583,\n",
       " 0.917752277,\n",
       " 0.91772737,\n",
       " 0.917593132,\n",
       " 0.917563123,\n",
       " 0.917532614,\n",
       " 0.917490302,\n",
       " 0.917471997,\n",
       " 0.917445089,\n",
       " 0.917415681,\n",
       " 0.917398176,\n",
       " 0.917396075,\n",
       " 0.917380271,\n",
       " 0.91737697,\n",
       " 0.917337158,\n",
       " 0.91727324,\n",
       " 0.917232629,\n",
       " 0.917159708,\n",
       " 0.917150005,\n",
       " 0.917128499,\n",
       " 0.917104692,\n",
       " 0.916928642,\n",
       " 0.91692444,\n",
       " 0.916911837,\n",
       " 0.916765295,\n",
       " 0.916586344,\n",
       " 0.916582243,\n",
       " 0.916500619,\n",
       " 0.916421196,\n",
       " 0.916396289,\n",
       " 0.916339473,\n",
       " 0.916317167,\n",
       " 0.91590815,\n",
       " 0.915712794,\n",
       " 0.915537744,\n",
       " 0.915432314,\n",
       " 0.915324883,\n",
       " 0.915286672,\n",
       " 0.915265366,\n",
       " 0.915214351,\n",
       " 0.915150433,\n",
       " 0.915110722,\n",
       " 0.915043803,\n",
       " 0.915012294,\n",
       " 0.914841745,\n",
       " 0.91471991,\n",
       " 0.914700404,\n",
       " 0.91465149,\n",
       " 0.914592273,\n",
       " 0.914514451,\n",
       " 0.914470238,\n",
       " 0.91440642,\n",
       " 0.914399118,\n",
       " 0.914353005,\n",
       " 0.914323096,\n",
       " 0.914306892,\n",
       " 0.914304991,\n",
       " 0.91426658,\n",
       " 0.914210364,\n",
       " 0.914163751,\n",
       " 0.914047017,\n",
       " 0.914001504,\n",
       " 0.913991602,\n",
       " 0.913781642,\n",
       " 0.913778741,\n",
       " 0.913771139,\n",
       " 0.913758335,\n",
       " 0.913734028,\n",
       " 0.913715623,\n",
       " 0.913692716,\n",
       " 0.913584885,\n",
       " 0.913547375,\n",
       " 0.913535771,\n",
       " 0.913518366,\n",
       " 0.91346275,\n",
       " 0.913446346,\n",
       " 0.913361821,\n",
       " 0.913255791,\n",
       " 0.913233785,\n",
       " 0.913160864,\n",
       " 0.913152862,\n",
       " 0.913050733,\n",
       " 0.913016323,\n",
       " 0.912961707,\n",
       " 0.912923596,\n",
       " 0.912800361,\n",
       " 0.912765551,\n",
       " 0.912739544,\n",
       " 0.912677826,\n",
       " 0.912641716,\n",
       " 0.912617509,\n",
       " 0.912509078,\n",
       " 0.912431956,\n",
       " 0.912426654,\n",
       " 0.912394645,\n",
       " 0.912228997,\n",
       " 0.912142473,\n",
       " 0.912111564,\n",
       " 0.912001332,\n",
       " 0.9118883,\n",
       " 0.911872295,\n",
       " 0.911860892,\n",
       " 0.911698746,\n",
       " 0.911625725,\n",
       " 0.911544002,\n",
       " 0.911519795,\n",
       " 0.911474282,\n",
       " 0.911453076,\n",
       " 0.911381955,\n",
       " 0.911337643,\n",
       " 0.911102775,\n",
       " 0.911074567,\n",
       " 0.910691958,\n",
       " 0.910654447,\n",
       " 0.910312249,\n",
       " 0.910084784,\n",
       " 0.910050374,\n",
       " 0.909981355,\n",
       " 0.909777096,\n",
       " 0.909709377,\n",
       " 0.909514921,\n",
       " 0.909171423,\n",
       " 0.908925453,\n",
       " 0.908857533,\n",
       " 0.908794215,\n",
       " 0.908677982,\n",
       " 0.908590457,\n",
       " 0.908536141,\n",
       " 0.908518436,\n",
       " 0.908451917,\n",
       " 0.908301374,\n",
       " 0.90818044,\n",
       " 0.908166536,\n",
       " 0.908156133,\n",
       " 0.907975181,\n",
       " 0.90762248,\n",
       " 0.907261577,\n",
       " 0.906843257,\n",
       " 0.906715921,\n",
       " 0.906535569,\n",
       " 0.906409833,\n",
       " 0.90608394,\n",
       " 0.905799259,\n",
       " 0.905695529,\n",
       " 0.905466563,\n",
       " 0.905144571,\n",
       " 0.905002131,\n",
       " 0.904982925,\n",
       " 0.904920207,\n",
       " 0.904877695,\n",
       " 0.904820979,\n",
       " 0.90475666,\n",
       " 0.904585411,\n",
       " 0.904536397,\n",
       " 0.904283625,\n",
       " 0.904199801,\n",
       " 0.903926923,\n",
       " 0.903870907,\n",
       " 0.903795686,\n",
       " 0.903782782,\n",
       " 0.903689455,\n",
       " 0.903453788,\n",
       " 0.903300244,\n",
       " 0.903010461,\n",
       " 0.902982853,\n",
       " 0.902787997,\n",
       " 0.90269267,\n",
       " 0.902173622,\n",
       " 0.902094599,\n",
       " 0.901942456,\n",
       " 0.901854931,\n",
       " 0.901681281,\n",
       " 0.901635568,\n",
       " 0.901549643,\n",
       " 0.901488226,\n",
       " 0.9013975,\n",
       " 0.901306674,\n",
       " 0.901246156,\n",
       " 0.90122415,\n",
       " 0.901191941,\n",
       " 0.90115253,\n",
       " 0.901126922,\n",
       " 0.901100315,\n",
       " 0.90098008,\n",
       " 0.900968677,\n",
       " 0.900914862,\n",
       " 0.900861046,\n",
       " 0.900821535,\n",
       " 0.900781123,\n",
       " 0.900718405,\n",
       " 0.900554959,\n",
       " 0.900538854,\n",
       " 0.900498042,\n",
       " 0.900494942,\n",
       " 0.90031639,\n",
       " 0.90014024,\n",
       " 0.9000013,\n",
       " 0.899604787,\n",
       " 0.899587582,\n",
       " 0.899554172,\n",
       " 0.899551972,\n",
       " 0.899469448,\n",
       " 0.899428337,\n",
       " 0.899381723,\n",
       " 0.899361317,\n",
       " 0.899238582,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = len(X)\n",
    "train_ratio = 0.8\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state = 100,max_iter = 1000,).fit(X[:,:int(num*train_ratio)],y[:,:int(num*train_ratio)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X[-int(num*(1-train_ratio)):,:])\n",
    "# X[int(num*train_ratio):,:]\n",
    "# X[:,:int(num*train_ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.672464\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1783\n",
      "Model:                          Logit   Df Residuals:                     1782\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -14.98\n",
      "Time:                        01:11:56   Log-Likelihood:                -1199.0\n",
      "converged:                       True   LL-Null:                       -75.050\n",
      "                                        LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0561      0.008     -6.721      0.000      -0.073      -0.040\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit = sta.Logit(F, A)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = []\n",
    "for i in range(len(A)):\n",
    "    X_1.append([A[i],B[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664198\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3566\n",
      "Model:                          Logit   Df Residuals:                     3564\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -14.78\n",
      "Time:                        01:31:42   Log-Likelihood:                -2368.5\n",
      "converged:                       True   LL-Null:                       -150.10\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0368      0.006     -6.264      0.000      -0.048      -0.025\n",
      "x2             0.0302      0.006      5.447      0.000       0.019       0.041\n",
      "==============================================================================\n",
      "[[0.95283784 0.97503239]\n",
      " [1.01953618 1.04195625]]\n",
      "[0.96387123 1.03068525]\n"
     ]
    }
   ],
   "source": [
    "logit = sta.Logit(F, X_1)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = []\n",
    "for i in range(len(A)):\n",
    "    X_2.append([A[i],B[i],C[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601398\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3566\n",
      "Model:                          Logit   Df Residuals:                     3563\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -13.29\n",
      "Time:                        01:32:37   Log-Likelihood:                -2144.6\n",
      "converged:                       True   LL-Null:                       -150.10\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1361      0.010    -13.346      0.000      -0.156      -0.116\n",
      "x2             0.0095      0.007      1.307      0.191      -0.005       0.024\n",
      "x3            -0.3880      0.025    -15.753      0.000      -0.436      -0.340\n",
      "==============================================================================\n",
      "[[0.85543677 0.89033819]\n",
      " [0.9952792  1.02394387]\n",
      " [0.64641007 0.71193898]]\n",
      "[0.87271303 1.0095098  0.67838376]\n"
     ]
    }
   ],
   "source": [
    "logit = sta.Logit(F, X_2)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = []\n",
    "for i in range(len(A)):\n",
    "    X_3.append([A[i],B[i],C[i],D[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600640\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3566\n",
      "Model:                          Logit   Df Residuals:                     3562\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -13.27\n",
      "Time:                        01:33:24   Log-Likelihood:                -2141.9\n",
      "converged:                       True   LL-Null:                       -150.10\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1540      0.013    -11.966      0.000      -0.179      -0.129\n",
      "x2             0.0044      0.008      0.578      0.563      -0.010       0.019\n",
      "x3            -0.3981      0.025    -15.793      0.000      -0.447      -0.349\n",
      "x4             0.0314      0.014      2.319      0.020       0.005       0.058\n",
      "==============================================================================\n",
      "[[0.83595251 0.87919755]\n",
      " [0.98957675 1.01943345]\n",
      " [0.63925568 0.7056395 ]\n",
      " [1.00487787 1.05968631]]\n",
      "[0.8573024  1.00439417 0.67162792 1.03191827]\n"
     ]
    }
   ],
   "source": [
    "logit = sta.Logit(F, X_3)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = []\n",
    "for i in range(len(A)):\n",
    "    X_4.append([A[i],B[i],C[i],D[i],E[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567240\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3566\n",
      "Model:                          Logit   Df Residuals:                     3561\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -12.48\n",
      "Time:                        01:34:09   Log-Likelihood:                -2022.8\n",
      "converged:                       True   LL-Null:                       -150.10\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1471      0.013    -11.569      0.000      -0.172      -0.122\n",
      "x2             0.0395      0.008      4.823      0.000       0.023       0.056\n",
      "x3            -0.4533      0.027    -17.063      0.000      -0.505      -0.401\n",
      "x4             0.0429      0.014      3.089      0.002       0.016       0.070\n",
      "x5            -0.1678      0.013    -12.965      0.000      -0.193      -0.142\n",
      "==============================================================================\n",
      "[[0.84197755 0.885003  ]\n",
      " [1.0237265  1.05712976]\n",
      " [0.603276   0.66949015]\n",
      " [1.01579551 1.07259045]\n",
      " [0.82431729 0.86722554]]\n",
      "[0.86322225 1.04029407 0.63552131 1.04380677 0.84549927]\n"
     ]
    }
   ],
   "source": [
    "logit = sta.Logit(F, X_4)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for i in range(len(y[-int(num*(1-train_ratio)):])):\n",
    "    y_true.append(list(y[-int(num*(1-train_ratio)):][i])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([837873432])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-int(num*train_ratio):][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[837669674,\n",
       " 837609156,\n",
       " 837437207,\n",
       " 836831434,\n",
       " 836722303,\n",
       " 836661285,\n",
       " 836557956,\n",
       " 836406212,\n",
       " 836226361,\n",
       " 836216158,\n",
       " 836002297,\n",
       " 835577975,\n",
       " 835575475,\n",
       " 835478947,\n",
       " 835257984,\n",
       " 835182362,\n",
       " 835083034,\n",
       " 834810856,\n",
       " 834803354,\n",
       " 834650710,\n",
       " 834575389,\n",
       " 834510570,\n",
       " 834376032,\n",
       " 834238692,\n",
       " 834045037,\n",
       " 833442164,\n",
       " 833441464,\n",
       " 833407254,\n",
       " 833128775,\n",
       " 833033748,\n",
       " 832557311,\n",
       " 832388163,\n",
       " 832364456,\n",
       " 832302438,\n",
       " 832221815,\n",
       " 832090478,\n",
       " 832086077,\n",
       " 831988249,\n",
       " 831909126,\n",
       " 831858011,\n",
       " 831783190,\n",
       " 831763384,\n",
       " 831316857,\n",
       " 831308554,\n",
       " 830620057,\n",
       " 829966871,\n",
       " 829599866,\n",
       " 829558154,\n",
       " 829420914,\n",
       " 829163041,\n",
       " 829126130,\n",
       " 828956081,\n",
       " 828213769,\n",
       " 827966498,\n",
       " 827896578,\n",
       " 827515970,\n",
       " 826951708,\n",
       " 826907195,\n",
       " 826824572,\n",
       " 826746449,\n",
       " 826625715,\n",
       " 826383646,\n",
       " 826380445,\n",
       " 826255809,\n",
       " 825958524,\n",
       " 825947621,\n",
       " 825755266,\n",
       " 825695049,\n",
       " 825605023,\n",
       " 825572014,\n",
       " 825519499,\n",
       " 825458481,\n",
       " 825336146,\n",
       " 825324643,\n",
       " 825299136,\n",
       " 825295635,\n",
       " 825286332,\n",
       " 825273628,\n",
       " 825127787,\n",
       " 825120384,\n",
       " 824977143,\n",
       " 824915526,\n",
       " 824902722,\n",
       " 824808195,\n",
       " 824692862,\n",
       " 823993962,\n",
       " 823607352,\n",
       " 823490618,\n",
       " 823480715,\n",
       " 823129315,\n",
       " 822730201,\n",
       " 822618469,\n",
       " 822589761,\n",
       " 822064911,\n",
       " 822048806,\n",
       " 821821241,\n",
       " 821640889,\n",
       " 821521955,\n",
       " 821347205,\n",
       " 821130443,\n",
       " 821032715,\n",
       " 821016811,\n",
       " 820810452,\n",
       " 820598691,\n",
       " 820592189,\n",
       " 820567782,\n",
       " 820526671,\n",
       " 820307508,\n",
       " 820222384,\n",
       " 820120254,\n",
       " 819908394,\n",
       " 819880086,\n",
       " 819850677,\n",
       " 819787059,\n",
       " 819395347,\n",
       " 819251306,\n",
       " 818856693,\n",
       " 818487988,\n",
       " 818452577,\n",
       " 817913323,\n",
       " 817597833,\n",
       " 817196318,\n",
       " 816564637,\n",
       " 816486215,\n",
       " 816413794,\n",
       " 816312265,\n",
       " 816172025,\n",
       " 815808221,\n",
       " 815783414,\n",
       " 815782914,\n",
       " 815686586,\n",
       " 815051805,\n",
       " 814219467,\n",
       " 813932485,\n",
       " 813554076,\n",
       " 813253891,\n",
       " 813195774,\n",
       " 812661821,\n",
       " 812650818,\n",
       " 812617809,\n",
       " 812198789,\n",
       " 812119666,\n",
       " 812099260,\n",
       " 811962321,\n",
       " 811141286,\n",
       " 811081569,\n",
       " 810902518,\n",
       " 810812792,\n",
       " 810723067,\n",
       " 810594030,\n",
       " 810458691,\n",
       " 810408677,\n",
       " 809983355,\n",
       " 809405290,\n",
       " 808182240,\n",
       " 807957976,\n",
       " 807825838,\n",
       " 807785927,\n",
       " 807780425,\n",
       " 807733212,\n",
       " 807561263,\n",
       " 807308690,\n",
       " 806965292,\n",
       " 806962391,\n",
       " 806922280,\n",
       " 805610905,\n",
       " 804658332,\n",
       " 804406260,\n",
       " 802984354,\n",
       " 802569435,\n",
       " 801894942,\n",
       " 801670278,\n",
       " 801272864,\n",
       " 801025493,\n",
       " 799939883,\n",
       " 799547571,\n",
       " 798912789,\n",
       " 798858774,\n",
       " 798696327,\n",
       " 798663818,\n",
       " 798452257,\n",
       " 798214389,\n",
       " 798207687,\n",
       " 798044241,\n",
       " 797709845,\n",
       " 797256015,\n",
       " 796947927,\n",
       " 796834595,\n",
       " 796033466,\n",
       " 795912031,\n",
       " 795585637,\n",
       " 795195926,\n",
       " 794536637,\n",
       " 794532936,\n",
       " 793713502,\n",
       " 793012702,\n",
       " 792789038,\n",
       " 792564974,\n",
       " 791524476,\n",
       " 791199483,\n",
       " 790824976,\n",
       " 790579006,\n",
       " 790232607,\n",
       " 789861500,\n",
       " 789791580,\n",
       " 789784578,\n",
       " 789525404,\n",
       " 789281635,\n",
       " 789252926,\n",
       " 789228019,\n",
       " 788929234,\n",
       " 788720174,\n",
       " 788329762,\n",
       " 788243738,\n",
       " 788094795,\n",
       " 786643580,\n",
       " 786278876,\n",
       " 785647195,\n",
       " 785049924,\n",
       " 784857169,\n",
       " 784368529,\n",
       " 784298909,\n",
       " 783746351,\n",
       " 783745251,\n",
       " 783354940,\n",
       " 783019444,\n",
       " 782748866,\n",
       " 781594436,\n",
       " 781336862,\n",
       " 780920143,\n",
       " 780598951,\n",
       " 779532246,\n",
       " 779141935,\n",
       " 778718013,\n",
       " 778195564,\n",
       " 777775444,\n",
       " 776057352,\n",
       " 775083374,\n",
       " 773684074,\n",
       " 771940075,\n",
       " 771281987,\n",
       " 771068826,\n",
       " 770970298,\n",
       " 770740032,\n",
       " 770575285,\n",
       " 770571884,\n",
       " 770261695,\n",
       " 770194376,\n",
       " 770047934,\n",
       " 769577499,\n",
       " 769335430,\n",
       " 769248905,\n",
       " 769207293,\n",
       " 768508393,\n",
       " 768312938,\n",
       " 767661451,\n",
       " 767517210,\n",
       " 765880842,\n",
       " 765741602,\n",
       " 764717609,\n",
       " 763795846,\n",
       " 762438357,\n",
       " 762188886,\n",
       " 762093159,\n",
       " 761141887,\n",
       " 760532212,\n",
       " 760195516,\n",
       " 759914936,\n",
       " 759622852,\n",
       " 759359577,\n",
       " 759252946,\n",
       " 758845130,\n",
       " 758712992,\n",
       " 758670780,\n",
       " 758583355,\n",
       " 758265964,\n",
       " 757634083,\n",
       " 757567364,\n",
       " 757539956,\n",
       " 757044015,\n",
       " 756949988,\n",
       " 756864863,\n",
       " 756695515,\n",
       " 755620107,\n",
       " 754629824,\n",
       " 754165591,\n",
       " 753665648,\n",
       " 753442485,\n",
       " 753309747,\n",
       " 751308374,\n",
       " 751065605,\n",
       " 750418220,\n",
       " 747659331,\n",
       " 737060499,\n",
       " 735083134,\n",
       " 734260298,\n",
       " 733906097,\n",
       " 732479689,\n",
       " 728723315,\n",
       " 726618213,\n",
       " 717818796,\n",
       " 715289373,\n",
       " 713185971,\n",
       " 711110978,\n",
       " 708826724,\n",
       " 708741700,\n",
       " 708459519,\n",
       " 706860262,\n",
       " 705476566,\n",
       " 704139584,\n",
       " 702492513,\n",
       " 702312161,\n",
       " 699582981,\n",
       " 697305929,\n",
       " 678021314,\n",
       " 676456266,\n",
       " 674911325,\n",
       " 671884459,\n",
       " 669422255,\n",
       " 666551934,\n",
       " 662532584,\n",
       " 656127853,\n",
       " 655732640,\n",
       " 655270507,\n",
       " 655005832,\n",
       " 654408861,\n",
       " 653542913,\n",
       " 652538426,\n",
       " 650198657,\n",
       " 649314304,\n",
       " 648820963,\n",
       " 646433880,\n",
       " 643149041,\n",
       " 641920789,\n",
       " 639334450,\n",
       " 473307266,\n",
       " 471647891,\n",
       " 469858279,\n",
       " 468237216,\n",
       " 467453192,\n",
       " 466666867,\n",
       " 461961221,\n",
       " 413925583,\n",
       " 409970952,\n",
       " 405710133,\n",
       " 402282553,\n",
       " 396871405,\n",
       " 388835707,\n",
       " 385480147,\n",
       " 81058983,\n",
       " 65041801,\n",
       " 50100529,\n",
       " 32976231,\n",
       " 25261825,\n",
       " 19176084,\n",
       " 13013822]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.560517\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                12494\n",
      "Model:                          Logit   Df Residuals:                    12493\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Tue, 29 Jan 2019   Pseudo R-squ.:                  -18.81\n",
      "Time:                        01:42:30   Log-Likelihood:                -7003.1\n",
      "converged:                       True   LL-Null:                       -353.45\n",
      "                                        LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.1806      0.004    -42.312      0.000      -0.189      -0.172\n",
      "==============================================================================\n",
      "[[0.82783661 0.84180219]]\n",
      "[0.83479019]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sta\n",
    "path = r'C:\\Users\\user\\Documents\\WeChat Files\\THU-TZR-CE-MATHS\\Files\\coeanfactor22.csv'\n",
    "raw_data = np.genfromtxt(path,delimiter = ',')\n",
    "\n",
    "A,B,C,D,E,F = [],[],[],[],[],[]\n",
    "\n",
    "for i in range(len(raw_data)):\n",
    "    A.append(raw_data[i][0])\n",
    "    B.append(raw_data[i][1])\n",
    "    C.append(raw_data[i][2])\n",
    "    D.append(raw_data[i][3])\n",
    "    E.append(raw_data[i][4])\n",
    "    F.append(raw_data[i][49])\n",
    "F[0] = 1\n",
    "X = np.array(D).reshape(-1,1)\n",
    "y = np.array(F).reshape(-1,1)\n",
    "\n",
    "logit = sta.Logit(F, D)\n",
    "results = logit.fit(maxiter = 1000)\n",
    "print(results.summary())\n",
    "print(np.exp(results.conf_int()))\n",
    "print(np.exp(results.params))\n",
    "\n",
    "# X_1 = []\n",
    "# for i in range(len(D)):\n",
    "#     X_1.append([D[i],B[i]])\n",
    "\n",
    "# logit = sta.Logit(F, X_1)\n",
    "# results = logit.fit(maxiter = 1000)\n",
    "# print(results.summary())\n",
    "# print(np.exp(results.conf_int()))\n",
    "# print(np.exp(results.params))\n",
    "\n",
    "# X_2 = []\n",
    "# for i in range(len(A)):\n",
    "#     X_2.append([A[i],B[i],C[i]])\n",
    "\n",
    "# logit = sta.Logit(F, X_2)\n",
    "# results = logit.fit(maxiter = 1000)\n",
    "# print(results.summary())\n",
    "# print(np.exp(results.conf_int()))\n",
    "# print(np.exp(results.params))\n",
    "\n",
    "# X_3 = []\n",
    "# for i in range(len(A)):\n",
    "#     X_3.append([A[i],B[i],C[i],D[i]])\n",
    "\n",
    "# logit = sta.Logit(F, X_3)\n",
    "# results = logit.fit(maxiter = 1000)\n",
    "# print(results.summary())\n",
    "# print(np.exp(results.conf_int()))\n",
    "# print(np.exp(results.params))\n",
    "\n",
    "# X_4 = []\n",
    "# for i in range(len(A)):\n",
    "#     X_4.append([A[i],B[i],C[i],D[i],E[i]])\n",
    "\n",
    "# logit = sta.Logit(F, X_4)\n",
    "# results = logit.fit(maxiter = 1000)\n",
    "# print(results.summary())\n",
    "# print(np.exp(results.conf_int()))\n",
    "# print(np.exp(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2da62cbca58>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(D,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
